{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Nested_Cross-Validation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"l6DaCCfxmPpz","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split\n","import numpy as np\n","from sklearn.externals import joblib"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kp_vhXLXmXSz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Number of random trials\n","NUM_TRIALS = 30 "],"execution_count":0,"outputs":[]},{"metadata":{"id":"xnMAYbNImaaB","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the dataset\n","features = pickle.load(open('/your/features','rb'))    \n","labels = pickle.load(open('/your/labels','rb'))\n","\n","features1 = np.empty((3322, 2048))\n","features1 = features\n","features1 = [[float(i) for i in l] for l in features] #removes apostrophes from array but turns into list  \n","\n","features = np.asarray(features1) # turn list back to array that can be parsed\n","labels = sorted(labels1)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FFg3esJxmxKj","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(features, labels,\n","                                                                        test_size=0.2, random_state=42)\n","\n","# Set up possible values of parameters to optimise over\n","p_grid = [\n","        {\n","            \"kernel\": [\"linear\"],\n","            \"C\": [1, 10, 100, 1000]\n","        },\n","        {\n","            \"kernel\": [\"rbf\"],\n","            \"C\": [1, 10, 100, 1000],\n","            \"gamma\": [1e-2, 1e-3, 1e-4, 1e-5]\n","        }\n","    ]\n","\n","# We will use a Support Vector Classifier with the above parameters to optimise over\n","svm = SVC(probability=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ND_--yOQnCdz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Arrays to store scores\n","non_nested_scores = np.zeros(NUM_TRIALS)\n","nested_scores = np.zeros(NUM_TRIALS)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KbHzhGbpm1gL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Loop for each trial\n","for i in range(NUM_TRIALS):\n","\n","    # Choose cross-validation techniques for the inner and outer loops,\n","    # independently of the dataset.\n","    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n","    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n","    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n","\n","    # Non_nested parameter search and scoring\n","    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n","    clf.fit(X_train, y_train)  \n","\n","    non_nested_scores[i] = clf.best_score_\n","    print(\"non-nested score : \", non_nested_scores[i])\n","    \n","    # Nested CV with parameter optimization\n","    nested_score = cross_val_score(clf, X=X_train, y=y_train, cv=outer_cv)\n","    nested_scores[i] = nested_score.mean()\n","    print(\"nested score : \", nested_scores[i])\n","\n","# let us know the training outcome - so we don't have to do it again!\n","print(\"\\nBest parameters set:\")\n","print(clf.best_params_)\n","\n","# save the C-SVC training results for future use\n","joblib.dump(clf.best_estimator_, '/you_dir/svc_estimator.pkl')\n","joblib.dump(clf, '/your_dir/svc_clf.pkl')\n","\n","\n","score_difference = non_nested_scores - nested_scores\n","\n","print(\"Average difference of {0:6f} with std. dev. of {1:6f}.\"\n","      .format(score_difference.mean(), score_difference.std()))"],"execution_count":0,"outputs":[]}]}
